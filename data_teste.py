#!/usr/bin/env python3
"""
Script otimizado para explorar dados minerados do GitHub
"""

import os
import pandas as pd
from datetime import datetime
from collections import Counter, defaultdict, deque
import heapq
from itertools import combinations

class DataExplorer:
    """Explorador de dados minerados"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.data = {}
        self.user_interactions = None
        self.user_degrees = None
        self.user_nodes = None
        
    def load_data(self):
        """Carrega todos os arquivos CSV"""
        files = {
            'issues': 'issues.csv',
            'pull_requests': 'pull_requests.csv',
            'comments': 'comments.csv',
            'reviews': 'reviews.csv'
        }
        
        cols_to_load = {
            'issues': ['author', 'assignees', 'number'],
            'pull_requests': ['author', 'assignees', 'number'],
            'comments': ['author', 'issue_number'],
            'reviews': ['author', 'pr_number']
        }
        
        for key, filename in files.items():
            filepath = os.path.join(self.data_dir, filename)
            if os.path.exists(filepath):
                try:
                    df = pd.read_csv(filepath, usecols=cols_to_load.get(key, None))
                    self.data[key] = df
                    print(f"‚úÖ {key}: {len(df)} registros carregados")
                except Exception as e:
                    print(f"‚ùå Erro ao carregar {filename}: {e}")
            else:
                print(f"‚ö†Ô∏è  Arquivo n√£o encontrado: {filename}")
    
    def build_interaction_graph(self):
        """Constr√≥i um grafo de intera√ß√µes"""
        if not self.data:
            print("‚ùå Nenhum dado carregado!")
            return None
            
        interactions = defaultdict(dict)
        degrees = defaultdict(int)
        
        self._preprocess_authors()
        
        self._process_issues(interactions, degrees)
        self._process_pull_requests(interactions, degrees)
        self._process_comments(interactions, degrees)
        self._process_reviews(interactions, degrees)
        
        self.user_interactions = dict(interactions)
        self.user_degrees = dict(degrees)
        self.user_nodes = set(interactions.keys())
        return interactions
    
    def _preprocess_authors(self):
        """Pr√©-processa autores para acesso r√°pido"""
        self.issue_authors = {}
        self.pr_authors = {}
        
        if 'issues' in self.data:
            self.issue_authors = dict(zip(
                self.data['issues']['number'],
                self.data['issues']['author']
            ))
        
        if 'pull_requests' in self.data:
            self.pr_authors = dict(zip(
                self.data['pull_requests']['number'],
                self.data['pull_requests']['author']
            ))
    
    def _process_issues(self, interactions, degrees):
        """Processa intera√ß√µes em issues de forma otimizada"""
        if 'issues' not in self.data:
            return
            
        issues_df = self.data['issues']
        issues_df = issues_df[['author', 'assignees']].dropna()
        
        for author, assignees_str in issues_df.itertuples(index=False):
            assignees = [a.strip() for a in assignees_str.split(',') if a.strip()]
            for assignee in assignees:
                interactions[author][assignee] = interactions[author].get(assignee, 0) + 1
                interactions[assignee][author] = interactions[assignee].get(author, 0) + 1
                degrees[author] += 1
                degrees[assignee] += 1
    
    def _process_pull_requests(self, interactions, degrees):
        """Processa intera√ß√µes em pull requests"""
        if 'pull_requests' not in self.data:
            return
            
        prs_df = self.data['pull_requests']
        prs_df = prs_df[['author', 'assignees']].dropna()
        
        for author, assignees_str in prs_df.itertuples(index=False):
            assignees = [a.strip() for a in assignees_str.split(',') if a.strip()]
            for assignee in assignees:
                interactions[author][assignee] = interactions[author].get(assignee, 0) + 1
                interactions[assignee][author] = interactions[assignee].get(author, 0) + 1
                degrees[author] += 1
                degrees[assignee] += 1
    
    def _process_comments(self, interactions, degrees):
        """Processa intera√ß√µes em coment√°rios"""
        if 'comments' not in self.data or not self.issue_authors:
            return
            
        comments_df = self.data['comments']
        comments_df = comments_df[['author', 'issue_number']].dropna()
        
        for author, issue_num in comments_df.itertuples(index=False):
            issue_author = self.issue_authors.get(issue_num)
            if issue_author and issue_author != author:
                interactions[author][issue_author] = interactions[author].get(issue_author, 0) + 1
                interactions[issue_author][author] = interactions[issue_author].get(author, 0) + 1
                degrees[author] += 1
                degrees[issue_author] += 1
    
    def _process_reviews(self, interactions, degrees):
        """Processa intera√ß√µes em reviews"""
        if 'reviews' not in self.data or not self.pr_authors:
            return
            
        reviews_df = self.data['reviews']
        reviews_df = reviews_df[['author', 'pr_number']].dropna()
        
        for author, pr_num in reviews_df.itertuples(index=False):
            pr_author = self.pr_authors.get(pr_num)
            if pr_author and pr_author != author:
                interactions[author][pr_author] = interactions[author].get(pr_author, 0) + 1
                interactions[pr_author][author] = interactions[pr_author].get(author, 0) + 1
                degrees[author] += 1
                degrees[pr_author] += 1
    
    def get_top_influencers(self, top_n=5):
        """Identifica os top_n usu√°rios mais influentes"""
        if self.user_degrees is None:
            self.build_interaction_graph()
        
        if not self.user_degrees:
            return []
        
        return heapq.nlargest(top_n, self.user_degrees.items(), key=lambda x: x[1])
    
    def identify_fragmentation_sources(self):
        """Vers√£o otimizada para identificar fontes de fragmenta√ß√£o"""
        if self.user_interactions is None:
            self.build_interaction_graph()
        
        if not self.user_interactions:
            return []
        
        fragmentation_scores = {}
        
        for user in self.user_interactions:
            neighbors = set(self.user_interactions[user].keys())
            degree = len(neighbors)
            
            if degree < 2:
                fragmentation_scores[user] = 0
                continue
                
            triangles = 0
            for n1, n2 in combinations(neighbors, 2):
                if n2 in self.user_interactions.get(n1, {}):
                    triangles += 1
            
            possible_triangles = degree * (degree - 1) / 2
            clustering_coeff = triangles / possible_triangles
            
            fragmentation_scores[user] = degree * (1 - clustering_coeff)
        
        return sorted(fragmentation_scores.items(), key=lambda x: x[1], reverse=True)
    
    def find_natural_groups(self):
        """Algoritmo otimizado para detec√ß√£o de comunidades"""
        if self.user_interactions is None:
            self.build_interaction_graph()
        
        if not self.user_interactions:
            return {}
        
        labels = {user: i for i, user in enumerate(self.user_interactions)}
        
        changed = True
        max_iter = 10
        current_iter = 0
        
        while changed and current_iter < max_iter:
            changed = False
            current_iter += 1
            
            nodes_ordered = sorted(self.user_interactions.keys(),
                                 key=lambda x: -len(self.user_interactions[x]))
            
            for node in nodes_ordered:
                if not self.user_interactions[node]:
                    continue
                    
                neighbor_labels = Counter()
                for neighbor in self.user_interactions[node]:
                    neighbor_labels[labels[neighbor]] += 1
                
                if not neighbor_labels:
                    continue
                
                most_common = neighbor_labels.most_common(1)[0][0]
                
                if labels[node] != most_common:
                    labels[node] = most_common
                    changed = True
        
        groups = defaultdict(list)
        for user, group_id in labels.items():
            groups[group_id].append(user)
        
        return dict(groups)
    
    def calculate_connection_level(self):
        """C√°lculo otimizado do n√≠vel de conex√£o"""
        if self.user_interactions is None:
            self.build_interaction_graph()
        
        if not self.user_interactions:
            return 0.0
        
        n = len(self.user_interactions)
        if n < 2:
            return 0.0
        
        existing_edges = sum(len(neighbors) for neighbors in self.user_interactions.values()) // 2
        
        max_edges = n * (n - 1) // 2
        
        return (existing_edges / max_edges) * 100
    
    def find_closest_users(self, user, top_n=5):
        """BFS otimizado para encontrar usu√°rios mais pr√≥ximos"""
        if self.user_interactions is None:
            self.build_interaction_graph()
        
        if user not in self.user_interactions:
            return []
        
        distances = {user: 0}
        queue = deque([user])
        
        while queue:
            current = queue.popleft()
            for neighbor in self.user_interactions[current]:
                if neighbor not in distances:
                    distances[neighbor] = distances[current] + 1
                    queue.append(neighbor)
        
        distances.pop(user)
        
        closest = heapq.nsmallest(top_n, distances.items(), key=lambda x: x[1])
        return closest
    
    def find_non_interacting_closest(self, user, top_n=5):
        """Vers√£o otimizada para encontrar pr√≥ximos n√£o interagentes"""
        if self.user_interactions is None:
            self.build_interaction_graph()
        
        if user not in self.user_interactions:
            return []
        
        direct_neighbors = set(self.user_interactions[user].keys())
        
        closest = self.find_closest_users(user, top_n + len(direct_neighbors))
        
        non_interacting = [(u, d) for u, d in closest if u not in direct_neighbors]
        
        return non_interacting[:top_n]
    
def generate_report(self, output_file: str = "data_report.txt"):
    """Gera relat√≥rio otimizado"""
    print(f"\nüìÑ Gerando relat√≥rio: {output_file}")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            # Cabe√ßalho do relat√≥rio
            f.write("RELAT√ìRIO DE AN√ÅLISE - VERS√ÉO OTIMIZADA\n")
            f.write("=" * 80 + "\n")
            f.write(f"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # Se√ß√£o de dados carregados
            f.write("DADOS CARREGADOS:\n")
            f.write("-" * 60 + "\n")
            f.write(f"Issues: {len(self.data.get('issues', [])):,} registros\n")
            f.write(f"Pull Requests: {len(self.data.get('pull_requests', [])):,} registros\n")
            f.write(f"Comments: {len(self.data.get('comments', [])):,} registros\n")
            f.write(f"Reviews: {len(self.data.get('reviews', [])):,} registros\n")
            f.write("\n")
            
            # 1. Top influentes
            f.write("\n1. TOP 5 USU√ÅRIOS MAIS INFLUENTES\n")
            f.write("-" * 60 + "\n")
            top_influencers = self.get_top_influencers(5)
            for i, (user, degree) in enumerate(top_influencers, 1):
                f.write(f"{i}. {user}: grau {degree}\n")
            
            # 2. Fragmenta√ß√£o
            f.write("\n2. PRINCIPAIS FONTES DE FRAGMENTA√á√ÉO\n")
            f.write("-" * 60 + "\n")
            f.write("""O score de fragmenta√ß√£o indica quanto um usu√°rio potencialmente divide a rede em comunidades separadas.
√â calculado considerando:
- Grau de conex√£o (n√∫mero de intera√ß√µes)
- Coeficiente de agrupamento (quanto os contatos do usu√°rio se conectam entre si)
- Quanto maior o score, maior o potencial de fragmenta√ß√£o

Score = Grau do Usu√°rio √ó (1 - Coeficiente de Agrupamento)
""")
            
            fragmenters = self.identify_fragmentation_sources()[:5]
            if fragmenters:
                avg_degree = sum(self.user_degrees.values()) / len(self.user_degrees) if self.user_degrees else 0
                f.write(f"\nM√©dia de conex√µes por usu√°rio: {avg_degree:.1f}\n\n")
                
                for i, (user, score) in enumerate(fragmenters, 1):
                    degree = self.user_degrees.get(user, 0)
                    clustering = 1 - (score / degree) if degree > 0 else 0
                    f.write(f"{i}. {user}:\n")
                    f.write(f"   - Score: {score:.2f}\n")
                    f.write(f"   - Conex√µes diretas: {degree}\n")
                    f.write(f"   - Agrupamento: {clustering:.3f}\n")
                    f.write(f"   - Conex√µes/Score: {degree/score:.1f}x\n\n")
                
                f.write("üîç Interpreta√ß√£o:\n")
                f.write("- Usu√°rios com alto score s√£o 'pontes' entre comunidades\n")
                f.write("- Remover esses usu√°rios aumentaria a separa√ß√£o entre grupos\n")
                f.write(f"- Valores acima de {avg_degree*2:.1f} indicam alta fragmenta√ß√£o\n")
            else:
                f.write("\nNenhuma fonte significativa de fragmenta√ß√£o identificada.\n")
            
            # 3. Grupos naturais
            f.write("\n3. GRUPOS NATURAIS (TOP 3)\n")
            f.write("-" * 60 + "\n")
            groups = self.find_natural_groups()
            if groups:
                sorted_groups = sorted(groups.items(), key=lambda x: -len(x[1]))[:3]
                for i, (group_id, members) in enumerate(sorted_groups, 1):
                    f.write(f"\nGrupo {i} ({len(members)} membros):\n")
                    f.write(", ".join(members[:5]))
                    if len(members) > 5:
                        f.write(", ...")
            else:
                f.write("Nenhum grupo identificado.\n")
            
            # 4. N√≠vel de conex√£o
            f.write("\n\n4. N√çVEL DE CONEX√ÉO DA COMUNIDADE\n")
            f.write("-" * 60 + "\n")
            connection_level = self.calculate_connection_level()
            f.write(f"{connection_level:.2f}% de conex√£o\n")
            
            # Rodap√©
            f.write("\n" + "=" * 80 + "\n")
            f.write("FIM DO RELAT√ìRIO\n")
        
        print(f"‚úÖ Relat√≥rio salvo em: {output_file}")
    
    except PermissionError:
        print(f"‚ùå Erro: Permiss√£o negada para escrever em {output_file}")
    except Exception as e:
        print(f"‚ùå Erro inesperado ao gerar relat√≥rio: {str(e)}")

def main():
    explorer = DataExplorer()
    
    print("üîç EXPLORADOR DE DADOS - VERS√ÉO OTIMIZADA")
    print("="*50)
    
    explorer.load_data()
    
    if not explorer.data:
        print("‚ùå Nenhum dado encontrado!")
        return
    
    print("\n‚è≥ Construindo grafo de intera√ß√µes...")
    explorer.build_interaction_graph()
    
    print("üìä Gerando relat√≥rio...")
    explorer.generate_report()

if __name__ == "__main__":
    main()