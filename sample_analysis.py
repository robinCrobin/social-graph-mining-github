#!/usr/bin/env python3
"""
Exemplo de an√°lises espec√≠ficas com os dados minerados
Este script demonstra como usar os dados para responder quest√µes espec√≠ficas
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import os

class NumPyAnalysis:
    """An√°lises espec√≠ficas do reposit√≥rio NumPy"""
    
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        self.issues_df = None
        self.prs_df = None
        self.comments_df = None
        self.reviews_df = None
        
    def load_data(self):
        """Carrega os dados minerados"""
        try:
            self.issues_df = pd.read_csv(os.path.join(self.data_dir, "issues.csv"))
            self.prs_df = pd.read_csv(os.path.join(self.data_dir, "pull_requests.csv"))
            self.comments_df = pd.read_csv(os.path.join(self.data_dir, "comments.csv"))
            self.reviews_df = pd.read_csv(os.path.join(self.data_dir, "reviews.csv"))
            
            # Converter datas
            for df in [self.issues_df, self.prs_df, self.comments_df, self.reviews_df]:
                if df is not None and 'created_at' in df.columns:
                    df['created_at'] = pd.to_datetime(df['created_at'])
            
            print("‚úÖ Dados carregados com sucesso!")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            return False
    
    def analyze_issue_resolution_time(self):
        """Analisa tempo de resolu√ß√£o de issues"""
        print("\nüïê AN√ÅLISE: Tempo de Resolu√ß√£o de Issues")
        print("="*50)
        
        if self.issues_df is None:
            print("‚ùå Dados de issues n√£o dispon√≠veis")
            return
        
        # Filtrar issues fechadas
        closed_issues = self.issues_df[
            (self.issues_df['state'] == 'CLOSED') & 
            (self.issues_df['closed_at'].notna())
        ].copy()
        
        if len(closed_issues) == 0:
            print("‚ùå Nenhuma issue fechada encontrada")
            return
        
        # Calcular tempo de resolu√ß√£o
        closed_issues['closed_at'] = pd.to_datetime(closed_issues['closed_at'])
        closed_issues['resolution_time'] = (
            closed_issues['closed_at'] - closed_issues['created_at']
        ).dt.days
        
        # Estat√≠sticas
        stats = closed_issues['resolution_time'].describe()
        
        print(f"üìä Estat√≠sticas de Tempo de Resolu√ß√£o (dias):")
        print(f"   Total de issues fechadas: {len(closed_issues):,}")
        print(f"   M√©dia: {stats['mean']:.1f} dias")
        print(f"   Mediana: {stats['50%']:.1f} dias")
        print(f"   M√≠nimo: {stats['min']:.0f} dias")
        print(f"   M√°ximo: {stats['max']:.0f} dias")
        
        # Categorizar por tempo
        categories = {
            'Muito R√°pido (< 1 dia)': len(closed_issues[closed_issues['resolution_time'] < 1]),
            'R√°pido (1-7 dias)': len(closed_issues[
                (closed_issues['resolution_time'] >= 1) & 
                (closed_issues['resolution_time'] <= 7)
            ]),
            'M√©dio (1-4 semanas)': len(closed_issues[
                (closed_issues['resolution_time'] > 7) & 
                (closed_issues['resolution_time'] <= 28)
            ]),
            'Lento (1-6 meses)': len(closed_issues[
                (closed_issues['resolution_time'] > 28) & 
                (closed_issues['resolution_time'] <= 180)
            ]),
            'Muito Lento (> 6 meses)': len(closed_issues[closed_issues['resolution_time'] > 180])
        }
        
        print(f"\nüìà Distribui√ß√£o por Categoria:")
        for category, count in categories.items():
            percentage = (count / len(closed_issues)) * 100
            print(f"   {category}: {count:,} ({percentage:.1f}%)")
    
    def analyze_pr_merge_patterns(self):
        """Analisa padr√µes de merge de Pull Requests"""
        print("\nüîÄ AN√ÅLISE: Padr√µes de Merge de Pull Requests")
        print("="*50)
        
        if self.prs_df is None:
            print("‚ùå Dados de PRs n√£o dispon√≠veis")
            return
        
        total_prs = len(self.prs_df)
        merged_prs = len(self.prs_df[self.prs_df['merged'] == True])
        closed_prs = len(self.prs_df[self.prs_df['state'] == 'CLOSED'])
        open_prs = len(self.prs_df[self.prs_df['state'] == 'OPEN'])
        
        print(f"üìä Estat√≠sticas Gerais:")
        print(f"   Total de PRs: {total_prs:,}")
        print(f"   PRs Merged: {merged_prs:,} ({(merged_prs/total_prs)*100:.1f}%)")
        print(f"   PRs Fechados: {closed_prs:,} ({(closed_prs/total_prs)*100:.1f}%)")
        print(f"   PRs Abertos: {open_prs:,} ({(open_prs/total_prs)*100:.1f}%)")
        
        # An√°lise de tamanho dos PRs
        merged_df = self.prs_df[self.prs_df['merged'] == True].copy()
        
        if len(merged_df) > 0:
            print(f"\nüìè An√°lise de Tamanho (PRs Merged):")
            print(f"   M√©dia de adi√ß√µes: {merged_df['additions'].mean():.0f} linhas")
            print(f"   M√©dia de dele√ß√µes: {merged_df['deletions'].mean():.0f} linhas")
            print(f"   M√©dia de arquivos alterados: {merged_df['changed_files'].mean():.1f}")
            
            # Categorizar por tamanho
            small_prs = len(merged_df[merged_df['additions'] + merged_df['deletions'] <= 50])
            medium_prs = len(merged_df[
                (merged_df['additions'] + merged_df['deletions'] > 50) & 
                (merged_df['additions'] + merged_df['deletions'] <= 500)
            ])
            large_prs = len(merged_df[merged_df['additions'] + merged_df['deletions'] > 500])
            
            print(f"\nüìä Distribui√ß√£o por Tamanho:")
            print(f"   Pequenos (‚â§ 50 linhas): {small_prs:,} ({(small_prs/len(merged_df))*100:.1f}%)")
            print(f"   M√©dios (51-500 linhas): {medium_prs:,} ({(medium_prs/len(merged_df))*100:.1f}%)")
            print(f"   Grandes (> 500 linhas): {large_prs:,} ({(large_prs/len(merged_df))*100:.1f}%)")
    
    def analyze_community_engagement(self):
        """Analisa engajamento da comunidade"""
        print("\nüë• AN√ÅLISE: Engajamento da Comunidade")
        print("="*50)
        
        # Coletar todos os contribuidores √∫nicos
        all_contributors = set()
        
        if self.issues_df is not None:
            all_contributors.update(self.issues_df['author'].dropna().unique())
            
        if self.prs_df is not None:
            all_contributors.update(self.prs_df['author'].dropna().unique())
            
        if self.comments_df is not None:
            all_contributors.update(self.comments_df['author'].dropna().unique())
            
        if self.reviews_df is not None:
            all_contributors.update(self.reviews_df['author'].dropna().unique())
        
        print(f"üë§ Total de contribuidores √∫nicos: {len(all_contributors):,}")
        
        # Analisar atividade por tipo
        activity_stats = {}
        
        if self.issues_df is not None:
            activity_stats['Issues criadas'] = len(self.issues_df)
            activity_stats['Autores √∫nicos de issues'] = self.issues_df['author'].nunique()
            
        if self.prs_df is not None:
            activity_stats['PRs criados'] = len(self.prs_df)
            activity_stats['Autores √∫nicos de PRs'] = self.prs_df['author'].nunique()
            
        if self.comments_df is not None:
            activity_stats['Comments feitos'] = len(self.comments_df)
            activity_stats['Autores √∫nicos de comments'] = self.comments_df['author'].nunique()
            
        if self.reviews_df is not None:
            activity_stats['Reviews feitos'] = len(self.reviews_df)
            activity_stats['Autores √∫nicos de reviews'] = self.reviews_df['author'].nunique()
        
        print(f"\nüìä Atividade por Tipo:")
        for activity, count in activity_stats.items():
            print(f"   {activity}: {count:,}")
    
    def analyze_popular_labels(self):
        """Analisa labels mais populares"""
        print("\nüè∑Ô∏è  AN√ÅLISE: Labels Mais Populares")
        print("="*50)
        
        all_labels = []
        
        # Coletar labels de issues
        if self.issues_df is not None:
            for labels_str in self.issues_df['labels'].dropna():
                if labels_str:
                    labels = [l.strip() for l in labels_str.split(',') if l.strip()]
                    all_labels.extend(labels)
        
        # Coletar labels de PRs
        if self.prs_df is not None:
            for labels_str in self.prs_df['labels'].dropna():
                if labels_str:
                    labels = [l.strip() for l in labels_str.split(',') if l.strip()]
                    all_labels.extend(labels)
        
        if all_labels:
            label_counts = Counter(all_labels)
            top_labels = label_counts.most_common(15)
            
            print(f"üìà Top 15 Labels Mais Usadas:")
            for i, (label, count) in enumerate(top_labels, 1):
                print(f"   {i:2d}. {label:<30} ({count:,} usos)")
        else:
            print("‚ùå Nenhuma label encontrada")
    
    def analyze_temporal_trends(self):
        """Analisa tend√™ncias temporais"""
        print("\nüìà AN√ÅLISE: Tend√™ncias Temporais")
        print("="*50)
        
        # Analisar atividade por ano
        yearly_activity = {}
        
        for name, df in [('Issues', self.issues_df), ('PRs', self.prs_df), 
                        ('Comments', self.comments_df), ('Reviews', self.reviews_df)]:
            if df is not None and 'created_at' in df.columns:
                yearly_counts = df.groupby(df['created_at'].dt.year).size()
                yearly_activity[name] = yearly_counts.to_dict()
        
        if yearly_activity:
            all_years = set()
            for activity in yearly_activity.values():
                all_years.update(activity.keys())
            
            all_years = sorted(all_years)
            
            print(f"üìä Atividade por Ano:")
            print(f"{'Ano':<6} {'Issues':<8} {'PRs':<8} {'Comments':<10} {'Reviews':<8}")
            print("-" * 50)
            
            for year in all_years:
                issues = yearly_activity.get('Issues', {}).get(year, 0)
                prs = yearly_activity.get('PRs', {}).get(year, 0)
                comments = yearly_activity.get('Comments', {}).get(year, 0)
                reviews = yearly_activity.get('Reviews', {}).get(year, 0)
                
                print(f"{year:<6} {issues:<8,} {prs:<8,} {comments:<10,} {reviews:<8,}")
    
    def generate_insights_report(self):
        """Gera relat√≥rio de insights"""
        print("\nüìÑ Gerando relat√≥rio de insights...")
        
        with open("numpy_insights.txt", "w", encoding="utf-8") as f:
            f.write("RELAT√ìRIO DE INSIGHTS - NUMPY/NUMPY\n")
            f.write("=" * 50 + "\n")
            f.write(f"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Estat√≠sticas b√°sicas
            f.write("ESTAT√çSTICAS B√ÅSICAS:\n")
            f.write("-" * 20 + "\n")
            
            if self.issues_df is not None:
                f.write(f"Issues: {len(self.issues_df):,}\n")
            if self.prs_df is not None:
                f.write(f"Pull Requests: {len(self.prs_df):,}\n")
            if self.comments_df is not None:
                f.write(f"Comments: {len(self.comments_df):,}\n")
            if self.reviews_df is not None:
                f.write(f"Reviews: {len(self.reviews_df):,}\n")
            
            f.write("\nEste relat√≥rio cont√©m an√°lises detalhadas do reposit√≥rio NumPy.\n")
            f.write("Execute o script sample_analysis.py para ver an√°lises completas.\n")
        
        print("‚úÖ Relat√≥rio salvo em: numpy_insights.txt")

def main():
    """Fun√ß√£o principal"""
    print("üî¨ AN√ÅLISES ESPEC√çFICAS - NUMPY/NUMPY")
    print("="*50)
    
    analyzer = NumPyAnalysis()
    
    if not analyzer.load_data():
        print("‚ùå N√£o foi poss√≠vel carregar os dados. Execute main.py primeiro.")
        return
    
    # Executar an√°lises
    try:
        analyzer.analyze_issue_resolution_time()
        analyzer.analyze_pr_merge_patterns()
        analyzer.analyze_community_engagement()
        analyzer.analyze_popular_labels()
        analyzer.analyze_temporal_trends()
        analyzer.generate_insights_report()
        
        print("\n‚úÖ An√°lises conclu√≠das!")
        print("üí° Veja os arquivos gerados para mais detalhes.")
        
    except Exception as e:
        print(f"‚ùå Erro durante as an√°lises: {e}")

if __name__ == "__main__":
    main() 